// core/hive.go

package core

import (
	"compress/gzip"
	"fmt"
	"io"
	"math/rand"
	"net/http"
	"net/url"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"time"

	"github.com/PuerkitoBio/goquery"
	"github.com/schollz/progressbar/v3"
)

// DownloadResult ä¸‹è½½ç»“æœ
type DownloadResult struct {
	Status   string // success, skip, failed
	Filename string
	Size     int64
	DOI      string
	Error    string
	Duration time.Duration
}

// DownloadStats ä¸‹è½½ç»Ÿè®¡
type DownloadStats struct {
	Total       int
	Success     int
	Skip        int
	Failed      int
	TotalSize   int64
	Errors      []DownloadError
	TotalTime   time.Duration   // æ€»è€—æ—¶ï¼ˆå¢™é’Ÿæ—¶é—´ï¼‰
	AllTimes    []time.Duration // æ‰€æœ‰ä»»åŠ¡çš„æ—¶é—´ï¼ˆåŒ…æ‹¬æˆåŠŸã€å¤±è´¥ã€è·³è¿‡ï¼‰
	SuccessTime []time.Duration // æˆåŠŸä»»åŠ¡çš„æ—¶é—´
}

// DownloadError ä¸‹è½½é”™è¯¯ä¿¡æ¯
type DownloadError struct {
	URL   string
	DOI   string
	Error string
	Time  time.Time
}

// DownloadPDFs æ‰¹é‡ä¸‹è½½ PDF æ–‡ä»¶
func DownloadPDFs(urls []string, pdfDir string, maxWorkers int) (*DownloadStats, error) {
	// ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
	if err := os.MkdirAll(pdfDir, 0755); err != nil {
		return nil, fmt.Errorf("æ— æ³•åˆ›å»º PDF ç›®å½•: %v", err)
	}

	stats := &DownloadStats{
		Total:       len(urls),
		Errors:      make([]DownloadError, 0),
		AllTimes:    make([]time.Duration, 0),
		SuccessTime: make([]time.Duration, 0),
	}

	// åˆ›å»ºå¤ç”¨çš„ HTTP å®¢æˆ·ç«¯ï¼ˆå¸¦è¿æ¥æ± ä¼˜åŒ–ï¼‰
	transport := &http.Transport{
		MaxIdleConns:        maxWorkers * 2, // æœ€å¤§ç©ºé—²è¿æ¥æ•°
		MaxIdleConnsPerHost: maxWorkers,     // æ¯ä¸ªä¸»æœºçš„æœ€å¤§ç©ºé—²è¿æ¥æ•°
		MaxConnsPerHost:     maxWorkers * 2, // æ¯ä¸ªä¸»æœºçš„æœ€å¤§è¿æ¥æ•°ï¼ˆåŒ…æ‹¬æ­£åœ¨ä½¿ç”¨çš„ï¼‰
		IdleConnTimeout:     90 * time.Second,
		DisableKeepAlives:   false, // å¯ç”¨è¿æ¥å¤ç”¨
		// å¯ç”¨ HTTP/2ï¼ˆå¦‚æœæœåŠ¡å™¨æ”¯æŒï¼Œå¯ä»¥æå‡æ€§èƒ½ï¼‰
		ForceAttemptHTTP2: true,
	}

	sharedClient := &http.Client{
		Transport: transport,
		Timeout:   15 * time.Second, // é¡µé¢è¯·æ±‚è¶…æ—¶
	}

	pdfClient := &http.Client{
		Transport: transport,
		Timeout:   120 * time.Second, // PDF ä¸‹è½½è¶…æ—¶ï¼ˆå¤§æ–‡ä»¶éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
	}

	// åˆ›å»º worker pool
	type jobWithTime struct {
		url       string
		startTime time.Time
	}
	jobs := make(chan jobWithTime, len(urls))
	results := make(chan DownloadResult, len(urls))

	// å¯åŠ¨ workers
	var wg sync.WaitGroup
	for i := 0; i < maxWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobs {
				result := downloadSinglePDF(job.url, pdfDir, sharedClient, pdfClient)
				// è®¡ç®—ä»æäº¤åˆ°å®Œæˆçš„æ€»æ—¶é—´ï¼ˆåŒ…æ‹¬ç­‰å¾…æ—¶é—´ï¼‰
				result.Duration = time.Since(job.startTime)
				results <- result
			}
		}()
	}

	// å¼€å§‹è®¡æ—¶ï¼ˆåœ¨å‘é€ä»»åŠ¡ä¹‹å‰ï¼‰
	startTime := time.Now()

	// å‘é€ä»»åŠ¡ï¼ˆè®°å½•æ¯ä¸ªä»»åŠ¡çš„æäº¤æ—¶é—´ï¼‰
	go func() {
		for _, u := range urls {
			jobs <- jobWithTime{
				url:       u,
				startTime: time.Now(),
			}
		}
		close(jobs)
	}()

	// ç­‰å¾…æ‰€æœ‰ workers å®Œæˆ
	go func() {
		wg.Wait()
		close(results)
	}()

	// åˆ›å»ºè¿›åº¦æ¡ï¼ˆä½¿ç”¨ stderr é¿å…ä¸ç»Ÿè®¡è¾“å‡ºå†²çªï¼‰
	bar := progressbar.NewOptions(
		len(urls),
		progressbar.OptionSetWriter(os.Stderr),
		progressbar.OptionSetWidth(40),
		progressbar.OptionShowCount(),
		progressbar.OptionSetDescription("ğŸ“¥ ä¸‹è½½ä¸­"),
		progressbar.OptionSetTheme(progressbar.Theme{
			Saucer:        "â–ˆ",
			SaucerHead:    "â–“",
			SaucerPadding: "â–‘",
			BarStart:      "â”‚",
			BarEnd:        "â”‚",
		}),
		progressbar.OptionShowElapsedTimeOnFinish(),
		progressbar.OptionSetPredictTime(true),
		progressbar.OptionSetRenderBlankState(true),
		progressbar.OptionOnCompletion(func() {
			fmt.Fprint(os.Stderr, "\n")
		}),
	)

	// æ”¶é›†ç»“æœ
	for result := range results {
		// è®°å½•æ‰€æœ‰ä»»åŠ¡çš„æ—¶é—´ï¼ˆåŒ…æ‹¬æˆåŠŸã€å¤±è´¥ã€è·³è¿‡ï¼‰
		stats.AllTimes = append(stats.AllTimes, result.Duration)

		switch result.Status {
		case "success":
			stats.Success++
			stats.TotalSize += result.Size
			stats.SuccessTime = append(stats.SuccessTime, result.Duration)
		case "skip":
			stats.Skip++
		case "failed":
			stats.Failed++
			stats.Errors = append(stats.Errors, DownloadError{
				URL:   fmt.Sprintf("https://sci-hub.se/%s", result.DOI),
				DOI:   result.DOI,
				Error: result.Error,
				Time:  time.Now(),
			})
		}

		// æ›´æ–°è¿›åº¦æ¡ï¼ˆåœ¨ç»Ÿè®¡æ›´æ–°åï¼‰
		bar.Add(1)

		// æ›´æ–°è¿›åº¦æ¡æè¿°ä»¥æ˜¾ç¤ºå®æ—¶ç»Ÿè®¡ï¼ˆæ·»åŠ é—´è·é¿å…é‡å ï¼‰
		desc := fmt.Sprintf("ğŸ“¥ âœ… %-3d â­ï¸ %-3d âŒ %-3d", stats.Success, stats.Skip, stats.Failed)
		bar.Describe(desc)
	}
	stats.TotalTime = time.Since(startTime)

	return stats, nil
}

// setBrowserHeaders è®¾ç½®å®Œæ•´çš„æµè§ˆå™¨è¯·æ±‚å¤´ï¼Œé¿å…è¢«è¯†åˆ«ä¸ºçˆ¬è™«
func setBrowserHeaders(req *http.Request) {
	// ä½¿ç”¨æ›´çœŸå®çš„ User-Agentï¼ˆå®šæœŸæ›´æ–°ä»¥åŒ¹é…æœ€æ–°æµè§ˆå™¨ç‰ˆæœ¬ï¼‰
	req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36")
	req.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7")
	req.Header.Set("Accept-Language", "en-US,en;q=0.9")
	req.Header.Set("Accept-Encoding", "gzip, deflate, br, zstd")
	req.Header.Set("Connection", "keep-alive")
	req.Header.Set("Upgrade-Insecure-Requests", "1")
	req.Header.Set("Sec-Fetch-Dest", "document")
	req.Header.Set("Sec-Fetch-Mode", "navigate")
	req.Header.Set("Sec-Fetch-Site", "none")
	req.Header.Set("Sec-Fetch-User", "?1")
	req.Header.Set("Cache-Control", "max-age=0")
	req.Header.Set("DNT", "1") // Do Not Track
	req.Header.Set("sec-ch-ua", `"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"`)
	req.Header.Set("sec-ch-ua-mobile", "?0")
	req.Header.Set("sec-ch-ua-platform", `"Windows"`)
}

// downloadSinglePDF ä¸‹è½½å•ä¸ª PDF æ–‡ä»¶
// æ³¨æ„ï¼šDuration å­—æ®µç”±è°ƒç”¨è€…è®¡ç®—ï¼ˆä»ä»»åŠ¡æäº¤åˆ°å®Œæˆçš„æ—¶é—´ï¼‰
func downloadSinglePDF(pageURL string, pdfDir string, client *http.Client, pdfClient *http.Client) DownloadResult {
	// è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºç»“æœï¼ˆDuration ç”±å¤–éƒ¨è®¡ç®—ï¼‰
	createResult := func(status, filename string, size int64, doi, errMsg string) DownloadResult {
		return DownloadResult{
			Status:   status,
			Filename: filename,
			Size:     size,
			DOI:      doi,
			Error:    errMsg,
			Duration: 0, // ç”±å¤–éƒ¨è®¡ç®—
		}
	}

	var err error

	// ä» URL ä¸­æå– DOI
	parsedURL, err := url.Parse(pageURL)
	if err != nil {
		return createResult("failed", "", 0, "", fmt.Sprintf("URL è§£æå¤±è´¥: %v", err))
	}

	doi := strings.TrimPrefix(parsedURL.Path, "/")

	// æ¸…ç† DOI ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œç”¨äºæ–‡ä»¶å
	safeFilename := strings.ReplaceAll(doi, "/", "_")
	safeFilename = strings.ReplaceAll(safeFilename, ":", "_")
	pdfFilename := safeFilename + ".pdf"

	pdfFilePath := filepath.Join(pdfDir, pdfFilename)

	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
	var info os.FileInfo
	info, err = os.Stat(pdfFilePath)
	if err == nil {
		return createResult("skip", pdfFilename, info.Size(), doi, "")
	}

	// æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«è¢«è¯†åˆ«ä¸ºçˆ¬è™«
	// å¦‚æœé‡åˆ° 403 é”™è¯¯ï¼Œå¢åŠ å»¶è¿Ÿæ—¶é—´
	delay := time.Duration(1000+rand.Intn(3000)) * time.Millisecond // 1.0-4.0 ç§’ï¼ˆå¢åŠ å»¶è¿Ÿï¼‰
	time.Sleep(delay)

	// ç¬¬ä¸€æ­¥ï¼šè·å–é¡µé¢ HTMLï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
	const maxRetries = 3
	retryDelay := 5 * time.Second // åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆå¢åŠ åˆ° 5 ç§’ï¼‰

	var resp *http.Response
	var req *http.Request
	for attempt := 0; attempt < maxRetries; attempt++ {
		req, err = http.NewRequest("GET", pageURL, nil)
		if err != nil {
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %v", err))
		}
		setBrowserHeaders(req)

		resp, err = client.Do(req)
		if err != nil {
			if attempt < maxRetries-1 {
				waitTime := retryDelay*time.Duration(attempt+1) + time.Duration(rand.Intn(2000))*time.Millisecond
				time.Sleep(waitTime)
				continue
			}
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("é¡µé¢è¯·æ±‚å¤±è´¥: %v (å·²é‡è¯• %d æ¬¡)", err, maxRetries))
		}

		// å¦‚æœæ˜¯ 403 é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•ï¼ˆå¢åŠ æ›´é•¿çš„å»¶è¿Ÿï¼‰
		if resp.StatusCode == http.StatusForbidden {
			resp.Body.Close()
			if attempt < maxRetries-1 {
				// æŒ‡æ•°é€€é¿ï¼š5s, 10s, 15s + éšæœº 0-5s
				waitTime := retryDelay*time.Duration(attempt+1) + time.Duration(rand.Intn(5000))*time.Millisecond
				time.Sleep(waitTime)
				continue
			}
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("é¡µé¢è¯·æ±‚å¤±è´¥: HTTP 403 (å·²é‡è¯• %d æ¬¡ï¼Œå¯èƒ½æ˜¯ IP è¢«å°ç¦)", maxRetries))
		}

		// å¯¹äº 404 é”™è¯¯ï¼Œå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œå¯ä»¥é‡è¯•ä¸€æ¬¡ï¼ˆå¯èƒ½æ˜¯ä¸´æ—¶é—®é¢˜ï¼‰
		if resp.StatusCode == http.StatusNotFound {
			resp.Body.Close()
			if attempt < maxRetries-1 {
				waitTime := retryDelay*time.Duration(attempt+1) + time.Duration(rand.Intn(2000))*time.Millisecond
				time.Sleep(waitTime)
				continue
			}
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("é¡µé¢è¯·æ±‚å¤±è´¥: HTTP 404 (é¡µé¢ä¸å­˜åœ¨ï¼Œå·²é‡è¯• %d æ¬¡)", maxRetries))
		}

		if resp.StatusCode != http.StatusOK {
			resp.Body.Close()
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("é¡µé¢è¯·æ±‚å¤±è´¥: HTTP %d", resp.StatusCode))
		}

		break // æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
	}

	if resp == nil {
		return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("é¡µé¢è¯·æ±‚å¤±è´¥: å·²é‡è¯• %d æ¬¡", maxRetries))
	}
	defer resp.Body.Close()

	// è¯»å– HTML å†…å®¹ï¼ˆå¤„ç† gzip å‹ç¼©ï¼‰
	var reader io.Reader = resp.Body
	if resp.Header.Get("Content-Encoding") == "gzip" {
		gzReader, err := gzip.NewReader(resp.Body)
		if err != nil {
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("è§£å‹ç¼©å¤±è´¥: %v", err))
		}
		defer gzReader.Close()
		reader = gzReader
	}

	htmlContent, err := io.ReadAll(reader)
	if err != nil {
		return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("è¯»å–é¡µé¢å†…å®¹å¤±è´¥: %v", err))
	}

	// è§£æ HTMLï¼ˆä½¿ç”¨è¯»å–çš„å†…å®¹ï¼‰
	doc, err := goquery.NewDocumentFromReader(strings.NewReader(string(htmlContent)))
	if err != nil {
		return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("HTML è§£æå¤±è´¥: %v", err))
	}

	// ç¬¬äºŒæ­¥ï¼šæå– PDF URLï¼ˆåŒæ—¶ä½¿ç”¨ goquery å’ŒåŸå§‹ HTMLï¼‰
	pdfURL := extractPDFURL(doc, string(htmlContent), pageURL)
	if pdfURL == "" {
		// æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥é¡µé¢å†…å®¹
		htmlStr := string(htmlContent)
		title := doc.Find("title").Text()

		// æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯é¡µé¢ï¼Œæä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
		errorMsg := "æœªèƒ½ä»é¡µé¢ä¸­æå– PDF URL"
		lowerHtml := strings.ToLower(htmlStr)
		lowerTitle := strings.ToLower(title)

		// ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ç« ä¸å¯ç”¨çš„æƒ…å†µ
		needDebug := true // æ˜¯å¦éœ€è¦ä¿å­˜ HTML ç”¨äºè°ƒè¯•
		if strings.Contains(lowerTitle, "article is not available") ||
			strings.Contains(lowerHtml, "article is not available") ||
			strings.Contains(lowerHtml, "not available through sci-hub") ||
			strings.Contains(lowerHtml, "not yet available in my database") {
			errorMsg = "æ–‡ç« åœ¨ Sci-Hub ä¸Šä¸å¯ç”¨"
			needDebug = false // æ–‡ç« ä¸å¯ç”¨æ˜¯æ­£å¸¸æƒ…å†µï¼Œä¸éœ€è¦ä¿å­˜ debug
		} else if strings.Contains(lowerHtml, "captcha") ||
			strings.Contains(lowerHtml, "are you a robot") ||
			strings.Contains(lowerHtml, "altcha-widget") ||
			strings.Contains(lowerTitle, "robot") {
			errorMsg += " (æ£€æµ‹åˆ°éªŒè¯ç )"
		} else if strings.Contains(lowerHtml, "not found") || strings.Contains(lowerHtml, "404") {
			errorMsg += " (é¡µé¢æœªæ‰¾åˆ°)"
			needDebug = false // 404 ä¹Ÿæ˜¯æ­£å¸¸æƒ…å†µ
		} else if title != "" {
			// å¦‚æœé¡µé¢æœ‰æ ‡é¢˜ï¼Œæ·»åŠ åˆ°é”™è¯¯ä¿¡æ¯ä¸­
			if len(title) > 50 {
				title = title[:50] + "..."
			}
			errorMsg += fmt.Sprintf(" (é¡µé¢æ ‡é¢˜: %s)", title)
		}

		// åªåœ¨éœ€è¦è°ƒè¯•æ—¶ä¿å­˜ HTMLï¼ˆæ’é™¤æ­£å¸¸çš„å¤±è´¥æƒ…å†µï¼‰
		if needDebug {
			debugDir := filepath.Join(pdfDir, "debug")
			os.MkdirAll(debugDir, 0755)
			debugFilename := strings.ReplaceAll(doi, "/", "_")
			debugFilename = strings.ReplaceAll(debugFilename, ":", "_")
			debugFile := filepath.Join(debugDir, fmt.Sprintf("%s.html", debugFilename))
			os.WriteFile(debugFile, htmlContent, 0644)
		}

		return createResult("failed", pdfFilename, 0, doi, errorMsg)
	}

	// ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½ PDF æ–‡ä»¶
	// æ·»åŠ éšæœºå»¶è¿Ÿï¼ˆå¢åŠ å»¶è¿Ÿæ—¶é—´ï¼‰
	delay = time.Duration(500+rand.Intn(1500)) * time.Millisecond // 0.5-2.0 ç§’
	time.Sleep(delay)

	// PDF ä¸‹è½½ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
	var pdfResp *http.Response
	for attempt := 0; attempt < maxRetries; attempt++ {
		req, err = http.NewRequest("GET", pdfURL, nil)
		if err != nil {
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("åˆ›å»º PDF è¯·æ±‚å¤±è´¥: %v", err))
		}
		setBrowserHeaders(req)
		// ä¸º PDF ä¸‹è½½æ·»åŠ  Referer å¤´
		req.Header.Set("Referer", pageURL)

		pdfResp, err = pdfClient.Do(req)
		if err != nil {
			if attempt < maxRetries-1 {
				waitTime := retryDelay*time.Duration(attempt+1) + time.Duration(rand.Intn(2000))*time.Millisecond
				time.Sleep(waitTime)
				continue
			}
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("PDF ä¸‹è½½å¤±è´¥: %v (å·²é‡è¯• %d æ¬¡)", err, maxRetries))
		}

		// å¦‚æœæ˜¯ 403 é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•ï¼ˆå¢åŠ æ›´é•¿çš„å»¶è¿Ÿï¼‰
		if pdfResp.StatusCode == http.StatusForbidden {
			pdfResp.Body.Close()
			if attempt < maxRetries-1 {
				// æŒ‡æ•°é€€é¿ï¼š5s, 10s, 15s + éšæœº 0-5s
				waitTime := retryDelay*time.Duration(attempt+1) + time.Duration(rand.Intn(5000))*time.Millisecond
				time.Sleep(waitTime)
				continue
			}
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("PDF ä¸‹è½½å¤±è´¥: HTTP 403 (å·²é‡è¯• %d æ¬¡ï¼Œå¯èƒ½æ˜¯ IP è¢«å°ç¦)", maxRetries))
		}

		if pdfResp.StatusCode != http.StatusOK {
			pdfResp.Body.Close()
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("PDF ä¸‹è½½å¤±è´¥: HTTP %d", pdfResp.StatusCode))
		}

		break // æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
	}

	if pdfResp == nil {
		return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("PDF ä¸‹è½½å¤±è´¥: å·²é‡è¯• %d æ¬¡", maxRetries))
	}
	defer pdfResp.Body.Close()

	// æ£€æŸ¥ Content-Typeï¼Œå¦‚æœä¸æ˜¯ PDF åˆ™æå‰æŠ¥é”™
	contentType := pdfResp.Header.Get("Content-Type")
	if contentType != "" && !strings.Contains(strings.ToLower(contentType), "pdf") && !strings.Contains(strings.ToLower(contentType), "application/octet-stream") {
		if strings.Contains(strings.ToLower(contentType), "html") || strings.Contains(strings.ToLower(contentType), "text") {
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("PDF ä¸‹è½½å¤±è´¥: æœåŠ¡å™¨è¿”å› HTML è€Œé PDF (Content-Type: %s)", contentType))
		}
	}

	// åˆ›å»ºä¸´æ—¶æ–‡ä»¶
	tmpFile, err := os.CreateTemp(pdfDir, "*.tmp")
	if err != nil {
		return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤±è´¥: %v", err))
	}
	tmpPath := tmpFile.Name()
	defer os.Remove(tmpPath)

	// å¤„ç†å¯èƒ½çš„ gzip å‹ç¼©
	var pdfReader io.Reader = pdfResp.Body
	if pdfResp.Header.Get("Content-Encoding") == "gzip" {
		gzReader, err := gzip.NewReader(pdfResp.Body)
		if err != nil {
			return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("PDF è§£å‹ç¼©å¤±è´¥: %v", err))
		}
		defer gzReader.Close()
		pdfReader = gzReader
	}

	// å†™å…¥æ–‡ä»¶
	written, err := io.Copy(tmpFile, pdfReader)
	tmpFile.Close()
	if err != nil {
		return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("å†™å…¥æ–‡ä»¶å¤±è´¥: %v", err))
	}

	// æ£€æŸ¥æ–‡ä»¶å¤§å°
	if written == 0 {
		return createResult("failed", pdfFilename, 0, doi, "ä¸‹è½½çš„æ–‡ä»¶å¤§å°ä¸º 0")
	}

	// éªŒè¯æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ PDFï¼ˆæ£€æŸ¥æ–‡ä»¶å¤´ï¼‰
	file, err := os.Open(tmpPath)
	if err != nil {
		return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("æ‰“å¼€æ–‡ä»¶å¤±è´¥: %v", err))
	}
	defer file.Close()

	header := make([]byte, 4)
	if _, err := file.Read(header); err != nil {
		return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("è¯»å–æ–‡ä»¶å¤´å¤±è´¥: %v", err))
	}

	if string(header) != "%PDF" {
		// æ£€æŸ¥æ˜¯å¦æ˜¯ HTML é”™è¯¯é¡µé¢
		file.Seek(0, 0)
		contentStart := make([]byte, 512)
		file.Read(contentStart)
		contentStr := strings.ToLower(string(contentStart))

		errorMsg := "ä¸‹è½½çš„æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ PDF æ–‡ä»¶"
		if strings.Contains(contentStr, "<html") || strings.Contains(contentStr, "<!doctype") {
			// å°è¯•æå–é”™è¯¯ä¿¡æ¯
			if strings.Contains(contentStr, "403") || strings.Contains(contentStr, "forbidden") {
				errorMsg += " (æ”¶åˆ° HTML 403 é”™è¯¯é¡µé¢)"
			} else if strings.Contains(contentStr, "404") || strings.Contains(contentStr, "not found") {
				errorMsg += " (æ”¶åˆ° HTML 404 é”™è¯¯é¡µé¢)"
			} else if strings.Contains(contentStr, "captcha") {
				errorMsg += " (æ”¶åˆ°éªŒè¯ç é¡µé¢)"
			} else {
				errorMsg += " (æ”¶åˆ° HTML é”™è¯¯é¡µé¢è€Œé PDF)"
			}
		} else if len(header) > 0 && header[0] == 0x1f && header[1] == 0x8b {
			errorMsg += " (æ–‡ä»¶æ˜¯ gzip å‹ç¼©æ ¼å¼ï¼Œå¯èƒ½æ˜¯ HTML é¡µé¢)"
		}

		return createResult("failed", pdfFilename, 0, doi, errorMsg)
	}

	// ç§»åŠ¨åˆ°æœ€ç»ˆä½ç½®
	if err := os.Rename(tmpPath, pdfFilePath); err != nil {
		return createResult("failed", pdfFilename, 0, doi, fmt.Sprintf("ç§»åŠ¨æ–‡ä»¶å¤±è´¥: %v", err))
	}

	return createResult("success", pdfFilename, written, doi, "")
}

// extractPDFURL ä» HTML ä¸­æå– PDF URL
// åŒæ—¶ä½¿ç”¨ goquery å’ŒåŸå§‹ HTML å­—ç¬¦ä¸²è¿›è¡Œæå–
func extractPDFURL(doc *goquery.Document, htmlContent string, baseURL string) string {
	base, err := url.Parse(baseURL)
	if err != nil {
		return ""
	}

	var pdfURL string
	var downloadURL string // ä¼˜å…ˆä¿å­˜ /download/ é“¾æ¥

	// æ–¹æ³•1ï¼šä¼˜å…ˆæŸ¥æ‰¾ä¸‹è½½é“¾æ¥ï¼ˆä¼˜å…ˆæŸ¥æ‰¾ /download/ è·¯å¾„ï¼‰
	doc.Find("div.download a").Each(func(i int, s *goquery.Selection) {
		if href, exists := s.Attr("href"); exists {
			if resolved := resolveURL(base, href); resolved != "" {
				// ä¼˜å…ˆé€‰æ‹©åŒ…å« /download/ çš„é“¾æ¥
				if strings.Contains(resolved, "/download/") {
					downloadURL = resolved
				} else if pdfURL == "" {
					// å¦‚æœæ²¡æœ‰æ‰¾åˆ° /download/ï¼Œä¿å­˜ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„
					pdfURL = resolved
				}
			}
		}
	})

	// ä¼˜å…ˆè¿”å› /download/ é“¾æ¥
	if downloadURL != "" {
		return downloadURL
	}
	if pdfURL != "" {
		return pdfURL
	}

	// æ–¹æ³•2ï¼šæŸ¥æ‰¾ object æ ‡ç­¾ï¼ˆtype='application/pdf'ï¼‰
	doc.Find("object[type='application/pdf']").Each(func(i int, s *goquery.Selection) {
		if pdfURL != "" {
			return
		}
		if data, exists := s.Attr("data"); exists {
			// ç§»é™¤ fragment
			if idx := strings.Index(data, "#"); idx != -1 {
				data = data[:idx]
			}
			if resolved := resolveURL(base, data); resolved != "" {
				pdfURL = resolved
			}
		}
	})

	if pdfURL != "" {
		return pdfURL
	}

	// æ–¹æ³•3ï¼šæŸ¥æ‰¾æ‰€æœ‰ object æ ‡ç­¾ï¼ˆå¤‡ç”¨ï¼‰
	doc.Find("object[data]").Each(func(i int, s *goquery.Selection) {
		if pdfURL != "" {
			return
		}
		if data, exists := s.Attr("data"); exists {
			// ç§»é™¤ fragment
			if idx := strings.Index(data, "#"); idx != -1 {
				data = data[:idx]
			}
			if resolved := resolveURL(base, data); resolved != "" {
				pdfURL = resolved
			}
		}
	})

	if pdfURL != "" {
		return pdfURL
	}

	// æ–¹æ³•4ï¼šæŸ¥æ‰¾ iframe æ ‡ç­¾ï¼ˆæŸäº›é¡µé¢ä½¿ç”¨ iframe åµŒå…¥ PDFï¼‰
	doc.Find("iframe[src]").Each(func(i int, s *goquery.Selection) {
		if pdfURL != "" {
			return
		}
		if src, exists := s.Attr("src"); exists {
			if resolved := resolveURL(base, src); resolved != "" {
				// åªæ¥å— PDF ç›¸å…³çš„ URL
				if strings.Contains(strings.ToLower(resolved), ".pdf") || strings.Contains(resolved, "/download/") {
					pdfURL = resolved
				}
			}
		}
	})

	if pdfURL != "" {
		return pdfURL
	}

	// æ–¹æ³•5ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»åŸå§‹ HTML ä¸­æå–ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
	// ä¼˜å…ˆæå– /download/ é“¾æ¥ï¼ˆä½¿ç”¨ DOTALL æ¨¡å¼åŒ¹é…å¤šè¡Œï¼‰
	downloadPattern := regexp.MustCompile(`(?is)<div[^>]*class\s*=\s*["']download["'][^>]*>.*?<a[^>]+href\s*=\s*["']([^"']+)["']`)
	if match := downloadPattern.FindStringSubmatch(htmlContent); len(match) > 1 {
		if resolved := resolveURL(base, match[1]); resolved != "" {
			return resolved
		}
	}

	// æå– object æ ‡ç­¾çš„ data å±æ€§ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
	objectPattern := regexp.MustCompile(`(?i)<object[^>]+data\s*=\s*["']([^"']+)["']`)
	if match := objectPattern.FindStringSubmatch(htmlContent); len(match) > 1 {
		data := match[1]
		if idx := strings.Index(data, "#"); idx != -1 {
			data = data[:idx]
		}
		if resolved := resolveURL(base, data); resolved != "" {
			return resolved
		}
	}

	// æ–¹æ³•6ï¼šæŸ¥æ‰¾æ‰€æœ‰åŒ…å« /download/ æˆ– .pdf çš„é“¾æ¥
	doc.Find("a[href]").Each(func(i int, s *goquery.Selection) {
		if pdfURL != "" {
			return
		}
		if href, exists := s.Attr("href"); exists {
			lowerHref := strings.ToLower(href)
			if strings.Contains(lowerHref, "/download/") || strings.Contains(lowerHref, ".pdf") {
				if resolved := resolveURL(base, href); resolved != "" {
					pdfURL = resolved
				}
			}
		}
	})

	if pdfURL != "" {
		return pdfURL
	}

	return ""
}

// resolveURL è§£æç›¸å¯¹ URL ä¸ºç»å¯¹ URLï¼ˆç±»ä¼¼ Python çš„ urljoinï¼‰
func resolveURL(base *url.URL, ref string) string {
	if ref == "" {
		return ""
	}

	// å¦‚æœæ˜¯ç»å¯¹ URLï¼Œç›´æ¥è¿”å›
	if strings.HasPrefix(ref, "http://") || strings.HasPrefix(ref, "https://") {
		return ref
	}

	// è§£æç›¸å¯¹è·¯å¾„
	refURL, err := url.Parse(ref)
	if err != nil {
		return ""
	}

	// åˆå¹¶ URLï¼ˆç±»ä¼¼ Python çš„ urljoinï¼‰
	resolved := base.ResolveReference(refURL)
	return resolved.String()
}
